---
title: "Project Log"
author: "Robert"
date: "11 6 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Project Abstract

We want to use 120 existing music test scores of 50 Songs as a base to build a recommender system for songs.

This system would observe (or rather question) a new user (e.g. age group, gender and let’s say 5 songs)

And then recommend a new song for the user - which he/she can then like or dislike? 
The level of likes for the recommended songs would be a suitable score for the quality of recommendations and thus the system.

2. Status quo (what we know and have, or could easily get)

We know something about 120 people, i.e. 
- age/demogroup
- gender
- if they were tested by CATI or CAWI (by telephone call or through an online survey)
- what genre they lean to among those tested (entry gate)
- how much time they spend daily listening to radio (light, normal, heavy users)
- which radiostations are their preferred stations (Stammsender (SS))
- if they also cume one of two other stations (Wechselsender (WS))

We have no prior information about the 50 songs tested, but we know their scores from
1 - I don’t know this song
2 - I know the song, but strongly dislike it
3 - I know the song and would tolerate it
4 - I don’t know how I feel about this song (discouraged in CATI)
5 - I know and like this song, but it is being played too often on the radio
6 - I know and like this song and I don’t think it is being played to often on the radio
7 - I know and love this song (which means, I don’t think it’s being played too often on the radio

We could probably get the audio features (10 Variables?) and number of streams for our 120 Songs from Spotify, if necessary.

3. What is there to do:

A) If we want to use the music test scores, the data has to be wrangled in order to get a suitable format. 
This would include:

- deciding, which variable are of interest, which have to be „translated in numeric format, and which have to be dummified“
- Building a function that enriches the song-data by adding the Spotify audio features figures (or a selection thereof)

B) Since we are probably going to have quite a few variables, a Principal Component Analysis PCA would have to reduce dimensions
- Building a PCA Procedure that allows us to capture at least X Percent of the variance in the dataset
- does this mean, that we are boiling down the song list for the dataset to X, in order not to have too many songs?
- which of the sociodemographic variables can be reduced?

C) A Cluster-Analysis 
- Deciding which distance measure to use (or rather reasoning, why one that would allow for a cluster algorithm to be applied is suitable
- Deciding (either heuristically or by dendrogram) how many clusters to calculate
- Performing a Cluster-Analysis on the data, probably by a k-means algorithm

D) Recommender System build
- creating a questionnaire environment that performs the test and (simple version: Spotify-List/Youtube Link / Scale 2:7, 1 not included)
- pipes the result to the recommender system
- which then returns a cluster and makes recommendation for the user for another song to be liked or disliked (again score 1 through 7?)
- extra credit: the score generated by that user is added to the database and makes the next recommendation even better (cycle?)

E) Presentation:
- Create a presentation to the project that takes the audience through the process
- Enable a live-demo that allows to audience to „get it“

## Different Approaches to Recommender Systems:

1.) Editorial and hand curated (list of favorites or "essential" items); not of interest to our approach as it doesn't involve user data
2.) Simple Aggregates (Top 10, Most Popular, Recent Uploads), not of interest to our approach as well, as it doesn't involve specific user data
3.) Tailored to individual users - this is of the most interest to us and will be our focus here:

The Formal Model includes 
C = A Set of Customers
S = A Set of Items (Songs, Movies, Books etc.)

Utility function or utility matrix u: C x S -> R, where
R = Set of Ratings
R is a totally ordered set
e.g., 0-5 stars, real number in [0,1]

A Utility Matrix gives you the ratings of Users (Rows) and their Items Scores (Columns)

Key Problems for Recommender Systems:

1) - How to collect the data in the utility matrix (already done in our case)
2) - Extrapolate unknown ratings from the known ones (especially the high ones, average and low ratings are really relevant for recommendations)
3) - Evaluation extrapolation methods (how to measure the performance of the recommender system)

ad 1 
- Explicit (Ask people to rate items -> doesn't scale well as only a fraction of users give ratings) - excellent data, but not sufficient
- Implicit (Learn ratings from user actions - e.g. purchase implies high ratings) - drawback: it's hard to gather low ratings
- Most use a combined approach of explicit and implicit ratings.
- cold start problem: new items have no ratings, new users have no ratings (Utility matrix U is sparse (most people have not rated most items))

Three Approaches to recommender systems:
1) Content-based
2) Collaborative (filtering)
3) Latent factor based

ad 1) Content-based Recommender System
Main Idea Recommend items to customer X similar to previous items rated highly by X. E.g. (Movies, Songs, Websites, News, People (with many common friends))
Plan of action is to find a set of items per user to build an item profile (like a specific actor) and then we are going to infer a user profile from this.
Once you have a user profile, we can match this with the catalogue and make recommendations. You can tell the user based on which item the reco was made.
The item profile can be thought of as a vector. We only have one item per user, which is the song score. Finding appropriate features is a problem for system.

ad 2) Collaborative Filtering

ad 3) Latent factor based - This one will most likely be the one where SVD, PCA and Eigenvektors will be used







